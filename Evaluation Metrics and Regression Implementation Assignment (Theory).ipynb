{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "986c1235-3594-46a0-b825-459ceb19372d",
      "cell_type": "code",
      "source": "                ### Evaluation Metrics and Regression Implementation Assignment (Theory) ###",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e87c554a-c47d-40f9-94c1-a8f7125d4931",
      "cell_type": "code",
      "source": "### Assignment Questions\n\n1. What does R-squared represent in a regression model?\n2. What are the assumptions of linear regression?\n3. What is the difference between R-squared and Adjusted R-squared?\n4. Why do we use Mean Squared Error (MSE)?\n5. What does an Adjusted R-squared value of 0.85 indicate?\n6. How do we check for normality of residuals in linear regression?\n7. What is multicollinearity, and how does it impact regression?\n8. What is Mean Absolute Error (MAE)?\n9. What are the benefits of using an ML. pipeline?\n10. Why is RMSE considered more interpretable than MSE?\n11. What is pickling in Python, and how is it useful in ML?\n12. What does a high R-squared value mean?\n13. What happens if linear regression assumptions are violated?\n14. How can we address multicollinearity in regression?\n15. How can feature selection improve model performance in regression analysis?\n16. How is Adjusted R-squared calculated?\n17. Why is MSE sensitive to outliers?\n18. What is the role of homoscedasticity in linear regression?\n19. What is Root Mean Squared Error (RMSE)?\n20. Why is pickling considered risky?\n21. What alternatives exist to pickling for saving ML models?\n22. What is heteroscedasticity, and why is it a problem?\n23. How can interaction terms enhance a regression model's predictive power?",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "24591583-7d09-4cab-af3c-df1a14349617",
      "cell_type": "code",
      "source": "Answer1:- R-squared represents the proportion of variance in the dependent variable that is predictable from the independent variable(s), ranging from 0 (no fit) to 1 (perfect fit).",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ff6e69bb-09a0-4fef-8a25-8b19954582a6",
      "cell_type": "code",
      "source": "Answer2:- The assumptions are:\n1. Linearity\n2. Independence\n3. Homoscedasticity\n4. Normality\n5. No multicollinearity",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "57b498ce-42b9-4d25-ba94-42036fa04745",
      "cell_type": "code",
      "source": "Answer3:- Adjusted R-squared penalizes models for adding unnecessary variables, providing a more accurate measure of model fit.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f1a61dd6-64e7-4278-b9e4-800cfc562724",
      "cell_type": "code",
      "source": "Answer4:- MSE measures the average squared difference between predicted and actual values, helping to evaluate model performance.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e0d4a776-4a27-44a1-aa87-859266147312",
      "cell_type": "code",
      "source": "Answer5:- An Adjusted R-squared value of 0.85 indicates that 85% of the variance in the dependent variable is predictable from the independent variable(s), adjusted for model complexity.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "59ab7d6a-dc75-4e4e-9281-fc7ec3f966c5",
      "cell_type": "code",
      "source": "Answer6:- Normality can be checked using:\n1. Q-Q plots\n2. Histograms\n3. Shapiro-Wilk test",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "97b3e6fc-df33-4bc5-9411-0a8c8e0f511e",
      "cell_type": "code",
      "source": "Answer7:- Multicollinearity occurs when independent variables are highly correlated, leading to unstable coefficient estimates and reduced model interpretability.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "138ce6e7-e219-4f2a-8e1f-6c51674bb1b5",
      "cell_type": "code",
      "source": "Answer8:- MAE measures the average absolute difference between predicted and actual values, providing a measure of model accuracy.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "eded10fa-e77b-4449-bffa-042dc1af33f0",
      "cell_type": "code",
      "source": "Answer9:- Benefits include:\n1. Streamlined workflow\n2. Improved reproducibility\n3. Efficient model development and deployment",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "93799814-7cca-45fa-b879-5d8881a53e13",
      "cell_type": "code",
      "source": "Answer10:- RMSE is in the same units as the dependent variable, making it more interpretable than MSE, which is in squared units.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4ebfb71a-8b13-43c8-bbb9-a697be1f380e",
      "cell_type": "code",
      "source": "Answer11:- Pickling is a serialization method that saves Python objects, including ML models, allowing for efficient storage and retrieval.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8cb68c47-838f-45db-9bc3-87dc2e8ef70d",
      "cell_type": "code",
      "source": "Answer12:- A high R-squared value indicates that a large proportion of variance in the dependent variable is predictable from the independent variable(s).",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6c1c2d22-934a-4625-9db2-fce1ddf76781",
      "cell_type": "code",
      "source": "Answer13:- Violating assumptions can lead to:\n1. Biased coefficient estimates\n2. Incorrect conclusions\n3. Poor model performance",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d4a38acd-7bc6-470c-90bf-86fd96ad1eae",
      "cell_type": "code",
      "source": "Answer14:- Methods include:\n1. Removing correlated variables\n2. Using dimensionality reduction techniques (e.g., PCA)\n3. Regularization techniques (e.g., Ridge, Lasso)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3ba550fa-be9a-4024-9751-a4b2708c03ab",
      "cell_type": "code",
      "source": "Answer15:- Feature selection can:\n1. Reduce overfitting\n2. Improve model interpretability\n3. Enhance predictive power",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4a116572-eae1-43cb-b7ba-0f11be4b9071",
      "cell_type": "code",
      "source": "Answer16:- Adjusted R-squared is calculated using the formula: 1 - (1 - RÂ²) * (n - 1) / (n - k - 1), where n is the sample size and k is the number of predictors.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8fece5a7-871b-4e66-875d-946118eadf75",
      "cell_type": "code",
      "source": "Answer17:- MSE squares the errors, giving more weight to large errors and making it sensitive to outliers.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0311bedb-d416-4ebf-8829-0e98e3714723",
      "cell_type": "code",
      "source": "Answer18:- Homoscedasticity ensures that the variance of residuals is constant across all levels of the independent variable, allowing for reliable inference.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "cb57e66a-2dc8-4d09-8d1b-5a976a1388c9",
      "cell_type": "code",
      "source": "Answer19:- RMSE is the square root of MSE, providing a measure of model accuracy in the same units as the dependent variable.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "7f6dd4a1-f50d-45cc-b1e8-f0f76e0961cf",
      "cell_type": "code",
      "source": "Answer20:- Pickling can be risky due to potential security vulnerabilities when unpickling untrusted data.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0d64e64b-203f-46e6-9020-aa5a6362e4b1",
      "cell_type": "code",
      "source": "Answer21:- Alternatives include:\n1. Joblib\n2. HDF5\n3. TensorFlow's SavedModel format",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0065d5ff-e61e-4aa7-898f-693168bff1a1",
      "cell_type": "code",
      "source": "Answer22:- Heteroscedasticity occurs when the variance of residuals varies across levels of the independent variable, leading to biased standard errors and incorrect conclusions.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e3a66fa3-c435-4fe1-8bd4-5d83dda41c0b",
      "cell_type": "code",
      "source": "Answer23:- Interaction terms allow the effect of one independent variable to depend on the level of another, capturing complex relationships and improving model accuracy.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}